<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>2.1 Manual maximum likelihood estimation | timeseRies</title>
  <meta name="description" content="Web complement of MATH 342 (Time series) at EPFL.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="2.1 Manual maximum likelihood estimation | timeseRies" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Web complement of MATH 342 (Time series) at EPFL." />
  <meta name="github-repo" content="lbelzile/timeseRies" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.1 Manual maximum likelihood estimation | timeseRies" />
  
  <meta name="twitter:description" content="Web complement of MATH 342 (Time series) at EPFL." />
  

<meta name="author" content="Léo Belzile">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="likelihood-estimation-and-the-boxjenkins-method.html">
<link rel="next" href="boxjenkins-methodology-for-arma-models.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Time Series</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preliminary remarks</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>1.1</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="1.1.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#libraries"><i class="fa fa-check"></i><b>1.1.1</b> Libraries</a></li>
<li class="chapter" data-level="1.1.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#loading-datasets"><i class="fa fa-check"></i><b>1.1.2</b> Loading datasets</a></li>
<li class="chapter" data-level="1.1.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#time-series-objects-and-basic-plots"><i class="fa fa-check"></i><b>1.1.3</b> Time series objects and basic plots</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-the-basic-time-series-functions.html"><a href="introduction-to-the-basic-time-series-functions.html"><i class="fa fa-check"></i><b>1.2</b> Introduction to the basic time series functions</a><ul>
<li class="chapter" data-level="1.2.1" data-path="introduction-to-the-basic-time-series-functions.html"><a href="introduction-to-the-basic-time-series-functions.html#exercise-1-beaver-temperature"><i class="fa fa-check"></i><b>1.2.1</b> Exercise 1: Beaver temperature</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="second-order-stationarity.html"><a href="second-order-stationarity.html"><i class="fa fa-check"></i><b>1.3</b> Second order stationarity</a><ul>
<li class="chapter" data-level="1.3.1" data-path="second-order-stationarity.html"><a href="second-order-stationarity.html#exercise-2-sp500-daily-returns"><i class="fa fa-check"></i><b>1.3.1</b> Exercise 2: SP500 daily returns</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="simulations.html"><a href="simulations.html"><i class="fa fa-check"></i><b>1.4</b> Simulations</a><ul>
<li class="chapter" data-level="1.4.1" data-path="simulations.html"><a href="simulations.html#exercise-3-simulated-data"><i class="fa fa-check"></i><b>1.4.1</b> Exercise 3: Simulated data</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="spectral-analysis.html"><a href="spectral-analysis.html"><i class="fa fa-check"></i><b>1.5</b> Spectral analysis</a></li>
<li class="chapter" data-level="1.6" data-path="smoothing-and-detrending.html"><a href="smoothing-and-detrending.html"><i class="fa fa-check"></i><b>1.6</b> Smoothing and detrending</a><ul>
<li class="chapter" data-level="1.6.1" data-path="smoothing-and-detrending.html"><a href="smoothing-and-detrending.html#exercise-4-mauna-loa-atmospheric-co2-concentration"><i class="fa fa-check"></i><b>1.6.1</b> Exercise 4: Mauna Loa Atmospheric CO<sub>2</sub> Concentration</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html"><i class="fa fa-check"></i><b>1.7</b> Solutions to Exercises</a><ul>
<li class="chapter" data-level="1.7.1" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#solutions-1-beaver-temperature"><i class="fa fa-check"></i><b>1.7.1</b> Solutions 1: Beaver temperature</a></li>
<li class="chapter" data-level="1.7.2" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#solutions-2-sp500-daily-returns"><i class="fa fa-check"></i><b>1.7.2</b> Solutions 2: SP500 daily returns</a></li>
<li class="chapter" data-level="1.7.3" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#solutions-3-simulated-data"><i class="fa fa-check"></i><b>1.7.3</b> Solutions 3: Simulated data</a></li>
<li class="chapter" data-level="1.7.4" data-path="solutions-to-exercises.html"><a href="solutions-to-exercises.html#solutions-4-mauna-loa-atmospheric-co2-concentration"><i class="fa fa-check"></i><b>1.7.4</b> Solutions 4: Mauna Loa Atmospheric CO<sub>2</sub> Concentration</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="likelihood-estimation-and-the-boxjenkins-method.html"><a href="likelihood-estimation-and-the-boxjenkins-method.html"><i class="fa fa-check"></i><b>2</b> Likelihood estimation and the Box–Jenkins method</a><ul>
<li class="chapter" data-level="2.1" data-path="manual-maximum-likelihood-estimation.html"><a href="manual-maximum-likelihood-estimation.html"><i class="fa fa-check"></i><b>2.1</b> Manual maximum likelihood estimation</a><ul>
<li class="chapter" data-level="2.1.1" data-path="manual-maximum-likelihood-estimation.html"><a href="manual-maximum-likelihood-estimation.html#exercise-1-ubs-stock-returns"><i class="fa fa-check"></i><b>2.1.1</b> Exercise 1: UBS stock returns</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="boxjenkins-methodology-for-arma-models.html"><a href="boxjenkins-methodology-for-arma-models.html"><i class="fa fa-check"></i><b>2.2</b> Box–Jenkins methodology for ARMA models</a><ul>
<li class="chapter" data-level="2.2.1" data-path="boxjenkins-methodology-for-arma-models.html"><a href="boxjenkins-methodology-for-arma-models.html#exercise-2-simulated-series"><i class="fa fa-check"></i><b>2.2.1</b> Exercise 2: Simulated series</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="information-criterion-model-selection-and-profile-likelihood.html"><a href="information-criterion-model-selection-and-profile-likelihood.html"><i class="fa fa-check"></i><b>2.3</b> Information criterion, model selection and profile likelihood</a><ul>
<li class="chapter" data-level="2.3.1" data-path="information-criterion-model-selection-and-profile-likelihood.html"><a href="information-criterion-model-selection-and-profile-likelihood.html#exercise-3-lake-erie-height"><i class="fa fa-check"></i><b>2.3.1</b> Exercise 3: Lake Erie height</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="solutions-to-exercises-1.html"><a href="solutions-to-exercises-1.html"><i class="fa fa-check"></i><b>2.4</b> Solutions to Exercises</a><ul>
<li class="chapter" data-level="2.4.1" data-path="solutions-to-exercises-1.html"><a href="solutions-to-exercises-1.html#exercise-1-ubs-stock-returns-1"><i class="fa fa-check"></i><b>2.4.1</b> Exercise 1: UBS stock returns</a></li>
<li class="chapter" data-level="2.4.2" data-path="solutions-to-exercises-1.html"><a href="solutions-to-exercises-1.html#exercise-2-simulated-series-1"><i class="fa fa-check"></i><b>2.4.2</b> Exercise 2: Simulated series</a></li>
<li class="chapter" data-level="2.4.3" data-path="solutions-to-exercises-1.html"><a href="solutions-to-exercises-1.html#exercise-3-lake-erie-height-1"><i class="fa fa-check"></i><b>2.4.3</b> Exercise 3: Lake Erie height</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="seasonal-arima-and-garch-models.html"><a href="seasonal-arima-and-garch-models.html"><i class="fa fa-check"></i><b>3</b> Seasonal ARIMA and GARCH models</a><ul>
<li class="chapter" data-level="3.1" data-path="sarima-models-estimation-and-forecasting.html"><a href="sarima-models-estimation-and-forecasting.html"><i class="fa fa-check"></i><b>3.1</b> SARIMA models: estimation and forecasting</a><ul>
<li class="chapter" data-level="3.1.1" data-path="sarima-models-estimation-and-forecasting.html"><a href="sarima-models-estimation-and-forecasting.html#mauna-loa-co2-dataset"><i class="fa fa-check"></i><b>3.1.1</b> Mauna Loa CO<sub>2</sub> dataset</a></li>
<li class="chapter" data-level="3.1.2" data-path="sarima-models-estimation-and-forecasting.html"><a href="sarima-models-estimation-and-forecasting.html#exercice-1-nottingham-average-monthly-temperature-and-hong-kong-monthly-exports"><i class="fa fa-check"></i><b>3.1.2</b> Exercice 1: Nottingham average monthly temperature and Hong Kong monthly exports</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="boostrap-methods-for-time-series.html"><a href="boostrap-methods-for-time-series.html"><i class="fa fa-check"></i><b>3.2</b> Boostrap methods for time series</a><ul>
<li class="chapter" data-level="3.2.1" data-path="boostrap-methods-for-time-series.html"><a href="boostrap-methods-for-time-series.html#bootstrapping-a-linear-model"><i class="fa fa-check"></i><b>3.2.1</b> Bootstrapping a linear model</a></li>
<li class="chapter" data-level="3.2.2" data-path="boostrap-methods-for-time-series.html"><a href="boostrap-methods-for-time-series.html#testing-for-heteroscedasticity"><i class="fa fa-check"></i><b>3.2.2</b> Testing for heteroscedasticity</a></li>
<li class="chapter" data-level="3.2.3" data-path="boostrap-methods-for-time-series.html"><a href="boostrap-methods-for-time-series.html#ar-sieve-bootstrap"><i class="fa fa-check"></i><b>3.2.3</b> AR-sieve bootstrap</a></li>
<li class="chapter" data-level="3.2.4" data-path="boostrap-methods-for-time-series.html"><a href="boostrap-methods-for-time-series.html#boostrap-models-for-uncertainty-assesment"><i class="fa fa-check"></i><b>3.2.4</b> Boostrap models for uncertainty assesment</a></li>
<li class="chapter" data-level="3.2.5" data-path="boostrap-methods-for-time-series.html"><a href="boostrap-methods-for-time-series.html#exercice-2-lake-erie-and-lake-huron-levels"><i class="fa fa-check"></i><b>3.2.5</b> Exercice 2: Lake Erie and Lake Huron levels</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="generalized-autoregressive-conditional-heteroskedasticity-garch-models-and-extensions.html"><a href="generalized-autoregressive-conditional-heteroskedasticity-garch-models-and-extensions.html"><i class="fa fa-check"></i><b>3.3</b> Generalized Autoregressive Conditional Heteroskedasticity (GARCH) models and extensions</a><ul>
<li class="chapter" data-level="3.3.1" data-path="generalized-autoregressive-conditional-heteroskedasticity-garch-models-and-extensions.html"><a href="generalized-autoregressive-conditional-heteroskedasticity-garch-models-and-extensions.html#predictions"><i class="fa fa-check"></i><b>3.3.1</b> Predictions</a></li>
<li class="chapter" data-level="3.3.2" data-path="generalized-autoregressive-conditional-heteroskedasticity-garch-models-and-extensions.html"><a href="generalized-autoregressive-conditional-heteroskedasticity-garch-models-and-extensions.html#exercice-3-international-business-machines-ibm-stock"><i class="fa fa-check"></i><b>3.3.2</b> Exercice 3: International Business Machines (IBM) stock</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="solutions-to-exercises-2.html"><a href="solutions-to-exercises-2.html"><i class="fa fa-check"></i><b>3.4</b> Solutions to Exercises</a><ul>
<li class="chapter" data-level="3.4.1" data-path="solutions-to-exercises-2.html"><a href="solutions-to-exercises-2.html#exercice-1-nottingham-average-monthly-temperature-and-hong-kong-monthly-exports-1"><i class="fa fa-check"></i><b>3.4.1</b> Exercice 1: Nottingham average monthly temperature and Hong Kong monthly exports</a></li>
<li class="chapter" data-level="3.4.2" data-path="solutions-to-exercises-2.html"><a href="solutions-to-exercises-2.html#exercice-2-lake-erie-and-lake-huron-levels-1"><i class="fa fa-check"></i><b>3.4.2</b> Exercice 2: Lake Erie and Lake Huron levels</a></li>
<li class="chapter" data-level="3.4.3" data-path="solutions-to-exercises-2.html"><a href="solutions-to-exercises-2.html#exercice-3-international-business-machines-ibm-stock-1"><i class="fa fa-check"></i><b>3.4.3</b> Exercice 3: International Business Machines (IBM) stock</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="spectral-analysis-and-filtering.html"><a href="spectral-analysis-and-filtering.html"><i class="fa fa-check"></i><b>4</b> Spectral analysis and filtering</a><ul>
<li class="chapter" data-level="4.1" data-path="nonparametric-spectral-estimation.html"><a href="nonparametric-spectral-estimation.html"><i class="fa fa-check"></i><b>4.1</b> Nonparametric spectral estimation</a><ul>
<li class="chapter" data-level="4.1.1" data-path="nonparametric-spectral-estimation.html"><a href="nonparametric-spectral-estimation.html#tapering"><i class="fa fa-check"></i><b>4.1.1</b> Tapering</a></li>
<li class="chapter" data-level="4.1.2" data-path="nonparametric-spectral-estimation.html"><a href="nonparametric-spectral-estimation.html#a-data-example"><i class="fa fa-check"></i><b>4.1.2</b> A data example</a></li>
<li class="chapter" data-level="4.1.3" data-path="nonparametric-spectral-estimation.html"><a href="nonparametric-spectral-estimation.html#smoothing"><i class="fa fa-check"></i><b>4.1.3</b> Smoothing</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="summary-of-nonparametric-spectral-estimation.html"><a href="summary-of-nonparametric-spectral-estimation.html"><i class="fa fa-check"></i><b>4.2</b> Summary of nonparametric spectral estimation</a></li>
<li class="chapter" data-level="4.3" data-path="spectral-estimation-in-r.html"><a href="spectral-estimation-in-r.html"><i class="fa fa-check"></i><b>4.3</b> Spectral estimation in R</a><ul>
<li class="chapter" data-level="4.3.1" data-path="spectral-estimation-in-r.html"><a href="spectral-estimation-in-r.html#smoothing-and-seasonally-adjusted-values"><i class="fa fa-check"></i><b>4.3.1</b> Smoothing and seasonally adjusted values</a></li>
<li class="chapter" data-level="4.3.2" data-path="spectral-estimation-in-r.html"><a href="spectral-estimation-in-r.html#exercise-1-southern-oscillation-index-soi-and-fish-recruitement"><i class="fa fa-check"></i><b>4.3.2</b> Exercise 1: Southern oscillation index (SOI) and fish recruitement</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="covariates-and-dynamic-linear-models.html"><a href="covariates-and-dynamic-linear-models.html"><i class="fa fa-check"></i><b>5</b> Covariates and dynamic linear models</a><ul>
<li class="chapter" data-level="5.1" data-path="simulation-based-prediction-intervals-for-arima-garch-models.html"><a href="simulation-based-prediction-intervals-for-arima-garch-models.html"><i class="fa fa-check"></i><b>5.1</b> Simulation-based prediction intervals for ARIMA-GARCH models</a></li>
<li class="chapter" data-level="5.2" data-path="state-space-models-and-the-kalman-filter.html"><a href="state-space-models-and-the-kalman-filter.html"><i class="fa fa-check"></i><b>5.2</b> State-space models and the Kalman filter</a><ul>
<li class="chapter" data-level="5.2.1" data-path="state-space-models-and-the-kalman-filter.html"><a href="state-space-models-and-the-kalman-filter.html#exercise-1-dynamic-linear-model-for-the-nile-river-dataset"><i class="fa fa-check"></i><b>5.2.1</b> Exercise 1: Dynamic linear model for the Nile river dataset</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="notes-on-irregular-time-series-and-missing-values.html"><a href="notes-on-irregular-time-series-and-missing-values.html"><i class="fa fa-check"></i><b>6</b> Notes on irregular time series and missing values&quot;</a><ul>
<li class="chapter" data-level="6.1" data-path="irregular-time-series.html"><a href="irregular-time-series.html"><i class="fa fa-check"></i><b>6.1</b> Irregular time series</a><ul>
<li class="chapter" data-level="6.1.1" data-path="irregular-time-series.html"><a href="irregular-time-series.html#exercise-1-jussy-air-temperature"><i class="fa fa-check"></i><b>6.1.1</b> Exercise 1: Jussy air temperature</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="imputation-of-missing-values.html"><a href="imputation-of-missing-values.html"><i class="fa fa-check"></i><b>6.2</b> Imputation of missing values</a><ul>
<li class="chapter" data-level="6.2.1" data-path="imputation-of-missing-values.html"><a href="imputation-of-missing-values.html#exercise-2-tyne-river-flow"><i class="fa fa-check"></i><b>6.2.1</b> Exercise 2: Tyne river flow</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="solutions-to-exercises-3.html"><a href="solutions-to-exercises-3.html"><i class="fa fa-check"></i><b>6.3</b> Solutions to Exercises</a><ul>
<li class="chapter" data-level="6.3.1" data-path="solutions-to-exercises-3.html"><a href="solutions-to-exercises-3.html#exercise-1-jussy-air-temperature-1"><i class="fa fa-check"></i><b>6.3.1</b> Exercise 1: Jussy air temperature</a></li>
<li class="chapter" data-level="6.3.2" data-path="solutions-to-exercises-3.html"><a href="solutions-to-exercises-3.html#exercise-2-tyne-river-flow-1"><i class="fa fa-check"></i><b>6.3.2</b> Exercise 2: Tyne river flow</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">timeseRies</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="manual-maximum-likelihood-estimation" class="section level2">
<h2><span class="header-section-number">2.1</span> Manual maximum likelihood estimation</h2>
<p>As was done in class for the <code>beaver</code> dataset, we will look at manual specification of the likelihood. While it is straightforward in principle to maximize the latter for ARMA models, the numerous restrictions that are imposed on the parameters make it hard, if not impossible, to manually code one’s own function. Maximum likelihood estimation is implemented typically via the state-space representation, which we will cover later in the semester.</p>
<p>For simple models, it is easily done however, and should shed some light on the various functions that are part of <strong>R</strong> for optimization, the definition of a function, the use of <code>nlm</code> and <code>optim</code> for optimization purposes, etc.</p>
<p>We first load a dataset of UBS and Credit Suisse stock prices from 2000 until 2008. The data is splitted in three parts for the analysis, since the data is heteroscedastic, and there appears (visually) to be two changepoints. We look at the adequacy of fitted AR(1) model for the mean and an ARCH(1) for the variance.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># devtools::install_github(&#39;nickpoison/astsa&#39;)</span>
<span class="co"># devtools::install_github(&#39;joshuaulrich/xts&#39;)</span>
<span class="kw">library</span>(xts)
<span class="kw">library</span>(lubridate)
<span class="co"># read data and examine it</span>
UBSCreditSuisse &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://sma.epfl.ch/~lbelzile/math342/UBSCSG.csv&quot;</span>, 
    <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)
<span class="kw">names</span>(UBSCreditSuisse)</code></pre>
<pre><code> [1] &quot;Date&quot;       &quot;UBS_OPEN&quot;   &quot;UBS_HIGH&quot;   &quot;UBS_LOW&quot;    &quot;UBS_LAST&quot;  
 [6] &quot;UBS_VOLUME&quot; &quot;CSG_OPEN&quot;   &quot;CSG_HIGH&quot;   &quot;CSG_LOW&quot;    &quot;CSG_LAST&quot;  
[11] &quot;CSG_VOLUME&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(UBSCreditSuisse)</code></pre>
<pre><code>    Date UBS_OPEN UBS_HIGH UBS_LOW UBS_LAST UBS_VOLUME CSG_OPEN CSG_HIGH
1 1/1/00       NA       NA      NA       NA         NA       NA       NA
2 1/2/00       NA       NA      NA       NA         NA       NA       NA
3 1/3/00       NA       NA      NA       NA         NA       NA       NA
4 1/4/00    31.13    31.17   30.32    30.32   11526322    72.01    72.13
5 1/5/00    30.06    31.06   29.73    30.32   17142124    67.51    69.01
6 1/6/00    30.29    30.80   30.25    30.47    9509228    68.09    68.55
  CSG_LOW CSG_LAST CSG_VOLUME
1      NA       NA         NA
2      NA       NA         NA
3      NA       NA         NA
4   69.13    69.24    5336924
5   67.40    68.44    4419160
6   67.74    68.55    2585800</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create time series, accounting for missing values at weekends and 251.25</span>
<span class="co"># values/year this is correct for analysis, but only provides approximate</span>
<span class="co"># locations for plotting</span>
UBS &lt;-<span class="st"> </span><span class="kw">ts</span>(UBSCreditSuisse<span class="op">$</span>UBS_LAST, <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">2000</span>, <span class="dv">1</span>), <span class="dt">frequency =</span> <span class="fl">365.25</span>)
UBS &lt;-<span class="st"> </span><span class="kw">ts</span>(UBS[<span class="op">!</span><span class="kw">is.na</span>(UBS)], <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">2000</span>, <span class="dv">1</span>), <span class="dt">frequency =</span> <span class="fl">251.625</span>)

<span class="co"># Irregular time series</span>
UBS_xts &lt;-<span class="st"> </span><span class="kw">with</span>(UBSCreditSuisse, <span class="kw">xts</span>(UBS_LAST, <span class="kw">mdy</span>(Date)))</code></pre>
<p>Objects of class <code>ts</code> store the dates from the vector start with observations as <span class="math inline">\((i-1)/\omega\)</span>. Thus, we specified in the above a vector encoded as 2000, 2000+1/365.25, This means that missing values are not handled. In contrast, <code>xts</code> objects keep the time stamps from a <code>Date</code> object. The function <code>with</code> is equivalent to <code>attach</code>, but has a limited scope and is used to avoid writing <code>UBSCreditSuisse$Date</code>, etc. The function <code>mdy</code> transforms the string <code>Date</code> as month, day and year. The string is coerced into an object of class <code>Date</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Analysis for UBS returns, 2000-2008</span>
UBS_ret &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span><span class="kw">diff</span>(<span class="kw">log</span>(UBS_xts))
<span class="kw">plot.zoo</span>(UBS_ret, <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>, <span class="dt">ylab =</span> (ylab &lt;-<span class="st"> &quot;Daily returns (in %)&quot;</span>), <span class="dt">main =</span> <span class="st">&quot;Percentage daily growth rate of UBS stock&quot;</span>)</code></pre>
<p><img src="timeseRies_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute log returns</span>
UBS.ret &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span><span class="kw">diff</span>(<span class="kw">log</span>(UBS))

<span class="co"># split into 3 homogeneous(?) parts, and plot using the same vertical axis</span>
<span class="co"># on the graphs</span>

<span class="co"># with the xts object</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))
lims &lt;-<span class="st"> </span><span class="kw">range</span>(UBS.ret)
<span class="kw">plot.zoo</span>(UBS_ret[<span class="kw">paste0</span>(<span class="kw">index</span>(<span class="kw">first</span>(UBS_ret)), <span class="st">&quot;/&quot;</span>, <span class="kw">as.Date</span>(<span class="st">&quot;2003-01-01&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="dv">100</span>)], <span class="dt">ylim =</span> lims, <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>, <span class="dt">ylab =</span> ylab)

<span class="co"># with window and the ts object</span>
y1 &lt;-<span class="st"> </span><span class="kw">window</span>(UBS.ret, <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2003</span>, <span class="dv">100</span>))
<span class="co"># plot(y1, ylim = lims)</span>

y2 &lt;-<span class="st"> </span><span class="kw">window</span>(UBS.ret, <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">2003</span>, <span class="dv">101</span>), <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2007</span>, <span class="dv">200</span>))
<span class="kw">plot</span>(y2, <span class="dt">ylim =</span> lims, <span class="dt">ylab =</span> ylab, <span class="dt">main =</span> <span class="st">&quot;UBS daily growth rate (in %)&quot;</span>)

y3 &lt;-<span class="st"> </span><span class="kw">window</span>(UBS.ret, <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">2007</span>, <span class="dv">201</span>))
<span class="kw">plot</span>(y3, <span class="dt">ylim =</span> lims, <span class="dt">ylab =</span> ylab)</code></pre>
<p><img src="timeseRies_files/figure-html/unnamed-chunk-10-2.png" width="672" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># analysis of first part, first just plotting ACF and PACF for data and for</span>
<span class="co"># abs(data)</span>
y &lt;-<span class="st"> </span>y1

<span class="co"># (Partial) correlograms for the series</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))
TSA<span class="op">::</span><span class="kw">acf</span>(y, <span class="dt">lag.max =</span> <span class="dv">100</span>, <span class="dt">main =</span> <span class="st">&quot;Daily log returns (%)&quot;</span>)
<span class="kw">pacf</span>(y, <span class="dt">lag.max =</span> <span class="dv">100</span>, , <span class="dt">main =</span> <span class="st">&quot;&quot;</span>)
TSA<span class="op">::</span><span class="kw">acf</span>(<span class="kw">abs</span>(y), <span class="dt">lag.max =</span> <span class="dv">100</span>, <span class="dt">main =</span> <span class="st">&quot;Absolute daily log returns (%)&quot;</span>)
<span class="kw">pacf</span>(<span class="kw">abs</span>(y), <span class="dt">lag.max =</span> <span class="dv">100</span>, <span class="dt">main =</span> <span class="st">&quot;&quot;</span>)</code></pre>
<p><img src="timeseRies_files/figure-html/unnamed-chunk-10-3.png" width="672" /></p>
<p>The residuals look pretty much white noise, but the variance has residual structure. Recall the implicit definition of the AR(1) process <span class="math inline">\(Y_t\)</span>, <span class="math display">\[Y_t=\mu+\phi(Y_{t-1}-\mu)+\varepsilon_t,\]</span>
where <span class="math inline">\(\varepsilon_t \stackrel{\mathrm{iid}}{\sim} \mathcal{N}(0,\sigma^2)\)</span>. The joint distribution of the observations conditional on the first is multivariate normal. Here is a simple function for the likelihood, which only requires specifying the conditional mean.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># analysis using AR(1) model for means conditional likelihood</span>
nll_AR1 &lt;-<span class="st"> </span><span class="cf">function</span>(th, y) {
    n &lt;-<span class="st"> </span><span class="kw">length</span>(y)
    condit.mean &lt;-<span class="st"> </span>th[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>th[<span class="dv">3</span>] <span class="op">*</span><span class="st"> </span>(y[<span class="op">-</span>n] <span class="op">-</span><span class="st"> </span>th[<span class="dv">1</span>])
    <span class="op">-</span><span class="kw">sum</span>(<span class="kw">dnorm</span>(y[<span class="op">-</span><span class="dv">1</span>], <span class="dt">mean =</span> condit.mean, <span class="dt">sd =</span> th[<span class="dv">2</span>], <span class="dt">log =</span> <span class="ot">TRUE</span>))
}
init1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.5</span>)
<span class="co"># fit1 &lt;- nlm(f = nll_AR1, p = init1, iterlim = 500, hessian = TRUE, y = y)</span>
fit1 &lt;-<span class="st"> </span><span class="kw">optim</span>(init1, nll_AR1, <span class="dt">y =</span> y, <span class="dt">hessian =</span> <span class="ot">TRUE</span>, <span class="dt">method =</span> <span class="st">&quot;Nelder-Mead&quot;</span>)</code></pre>
<p>We obtain the parameter estimates and the standard errors from the observed information matrix, estimated numerically. Incidently, one can easily that the problem is equivalent to a linear Gaussian model where the regressor is a lagged vector of observations. The parameter estimates differ slightly, but this is due to the optimization routine.</p>
<pre class="ar1_param"><code>#Parameter values (MLEs)
fit1$par
#Standard errors from inverse of Hessian matrix at MLE
#If you code the optimization routine yourself, you can still obtain the Hessian via
#hessian &lt;- numDeriv::hessian(func = nll_AR1, y = y, x = fit1$par)

#Standard errors
sqrt(diag(solve(fit1$hessian)))

#Conditional likelihood using lm 
#dynlm is a wrapper around lm for `ts` and `zoo` objects, L means lag and you can add e.g. trend(y)
fit1_ols &lt;- dynlm::dynlm(y ~ L(y, 1))
coefficients(fit1_ols)
sd(residuals(fit1_ols))</code></pre>
<p>Incidently, the situation is analogous for the ARCH(1) process, which has a conditional variance that changes over time. The latter is defined implicitly as
<span class="math display">\[\begin{align*}
Z_t &amp;= \mu + \sigma_t\epsilon_t\\
\sigma_t^2 &amp;=\alpha_0+\alpha_1(Z_{t-1}-\mu)^2 
\end{align*}\]</span>
with <span class="math inline">\(\epsilon_t \stackrel{\mathrm{iid}}{\sim} \mathcal{N}(0, 1)\)</span>.</p>
<p>The variance <span class="math inline">\(\sigma^2\)</span> here is included as <span class="math inline">\(\sigma^2=\alpha_0\)</span> and the parameter appearing in the likelihood is <span class="math inline">\(\alpha_1/\sigma^2\)</span> corresponds to <span class="math inline">\(\theta_3\)</span>, or <code>th[3]</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># analysis using ARCH(1) model for variances</span>
nll_ARCH1 &lt;-<span class="st"> </span><span class="cf">function</span>(th, y) {
    n &lt;-<span class="st"> </span><span class="kw">length</span>(y)
    condit.mean &lt;-<span class="st"> </span>th[<span class="dv">1</span>]
    condit.var &lt;-<span class="st"> </span>th[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>th[<span class="dv">3</span>] <span class="op">*</span><span class="st"> </span>(y[<span class="op">-</span>n] <span class="op">-</span><span class="st"> </span>th[<span class="dv">1</span>])<span class="op">^</span><span class="dv">2</span>)
    <span class="op">-</span><span class="kw">sum</span>(<span class="kw">dnorm</span>(y[<span class="op">-</span><span class="dv">1</span>], <span class="dt">mean =</span> condit.mean, <span class="dt">sd =</span> <span class="kw">sqrt</span>(condit.var), <span class="dt">log =</span> <span class="ot">TRUE</span>))
}
init2 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.5</span>)
fit2 &lt;-<span class="st"> </span><span class="kw">nlm</span>(<span class="dt">f =</span> nll_ARCH1, <span class="dt">p =</span> init2, <span class="dt">iterlim =</span> <span class="dv">500</span>, <span class="dt">hessian =</span> <span class="ot">TRUE</span>, <span class="dt">y =</span> y)
<span class="co">## fit2 &lt;- optim(init2, nll_ARCH1, y = y, hessian = TRUE)</span></code></pre>
<p>The function <code>nlm</code> performs minimization, but may return warnings because some of its steps because the conditional variance can be negative for some combinations of the variable, so the corresponding moves of the Newton algorithm are rejected. These are typically steps that are not in the neighborhood of the final solution, so can be ignored if the output is valid. The <code>minimum</code> corresponds to the negative log-likelihood at the maximum likelihood estimates. The MLE is given by <code>estimate</code> and the standard errors by the square root of the diagonal entries of the inverse Hessian (here already negated because we work with the negative of the log-likelihood). Since the residuals have a varying variance, we need to adjust them by dividing each by their respective variance. Same would have occured for the AR(1) process, but it is easier for the mean.</p>
<pre class="sourceCode r"><code class="sourceCode r">fit2<span class="op">$</span>minimum</code></pre>
<pre><code>[1] 1860.386</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">fit2<span class="op">$</span>estimate</code></pre>
<pre><code>[1] 0.02691498 3.31180313 0.11770094</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">solve</span>(fit2<span class="op">$</span>hessian)))</code></pre>
<pre><code>[1] 0.06843004 0.24664944 0.02908274</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">make_resid_ARCH1 &lt;-<span class="st"> </span><span class="cf">function</span>(y, fit) {
    th &lt;-<span class="st"> </span>fit<span class="op">$</span>estimate
    n &lt;-<span class="st"> </span><span class="kw">length</span>(y)
    condit.mean &lt;-<span class="st"> </span>th[<span class="dv">1</span>]
    condit.var &lt;-<span class="st"> </span>th[<span class="dv">2</span>] <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>th[<span class="dv">3</span>] <span class="op">*</span><span class="st"> </span>(y[<span class="op">-</span>n] <span class="op">-</span><span class="st"> </span>th[<span class="dv">1</span>])<span class="op">^</span><span class="dv">2</span>)
    res &lt;-<span class="st"> </span>(y[<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>condit.mean)<span class="op">/</span><span class="kw">sqrt</span>(condit.var)
    <span class="kw">ts</span>(res)
}

res2 &lt;-<span class="st"> </span><span class="kw">make_resid_ARCH1</span>(y, fit2)</code></pre>
<p>We now proceed with diagnostic plots to check the model adequacy. Recall that the Kolmogorov–Smirnov test statistic associated with
the cumulative periodogram tests the hypothesis of white noise (and ARCH(1) is white noise).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(y, <span class="dt">main =</span> <span class="st">&quot;Raw returns&quot;</span>)
<span class="kw">plot</span>(res2, <span class="dt">main =</span> <span class="st">&quot;ARCH(1) residuals&quot;</span>)
<span class="kw">cpgram</span>(res2, <span class="dt">main =</span> <span class="st">&quot;Cumulative periodogram&quot;</span>)
<span class="kw">par</span>(<span class="dt">pty =</span> <span class="st">&quot;s&quot;</span>)
<span class="kw">qqnorm</span>(res2, <span class="dt">panel.first =</span> {
    <span class="kw">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)
})</code></pre>
<p><img src="timeseRies_files/figure-html/diagnostics_ARCH-1.png" width="672" /></p>
<div id="exercise-1-ubs-stock-returns" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Exercise 1: UBS stock returns</h3>
<ol style="list-style-type: decimal">
<li>Create a function that fits an AR(1)-ARCH(1) model by modifying the code provided above and apply it to <code>y</code>. The latter is defined as
<span class="math display">\[Y_t-\mu = \phi(Y_{t-1}-\mu)+\sigma_t\varepsilon_t, \quad \sigma^2_t = \alpha_0+\alpha_1(Y_{t-1}-\mu)^2, \quad \varepsilon_t \stackrel{\mathrm{iid}}{\sim} \mathcal{N}(0,\sigma^2)\]</span></li>
<li>Obtain the maximum likelihood estimates using <code>nlm</code> or <code>optim</code> as well as the standard errors</li>
<li>Plot the residuals. Comment on the fit using standard diagnostic plots (Q-Q plot, ((P)ACF, cumulative periodogram).</li>
<li>Fit an AR(2) model using a conditional likelihood for the mean and obtain the standard errors of your estimated coefficients.</li>
<li>Perform a likelihood ratio test to test whether the AR(2) coefficient is significative.</li>
</ol>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="likelihood-estimation-and-the-boxjenkins-method.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="boxjenkins-methodology-for-arma-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["timeseRies.pdf", "timeseRies.epub"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
